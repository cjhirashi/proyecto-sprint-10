# üè¶ Proyecto Sprint 10 - Predicci√≥n de Churn en Beta Bank

[![Python](https://img.shields.io/badge/Python-3.11-blue?logo=python)](https://www.python.org/)
[![Pandas](https://img.shields.io/badge/Pandas-Data%20Analysis-green?logo=pandas)](https://pandas.pydata.org/)
[![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-ML%20Models-orange?logo=scikitlearn)](https://scikit-learn.org/stable/)
[![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange?logo=jupyter)](https://jupyter.org/)

---

## üöÄ Descripci√≥n

Proyecto del **Sprint 10** en **TripleTen**. Desarrollo de un modelo de **Machine Learning** para predecir la salida de clientes (**churn**) en **Beta Bank**. El modelo debe alcanzar un valor **F1 ‚â• 0.59** y se comparar√° con la m√©trica **AUC-ROC**.

---

## ‚ú® Objetivos principales

* Analizar y preparar los datos de clientes de Beta Bank.
* Explorar el desbalance de clases en la variable objetivo `Exited`.
* Entrenar modelos de clasificaci√≥n sin correcci√≥n de desbalance.
* Aplicar al menos **dos t√©cnicas de balanceo** (sobremuestreo, submuestreo, `class_weight`).
* Comparar y seleccionar el mejor modelo en validaci√≥n.
* Evaluar resultados en conjunto de prueba.

---

## üß∞ Tecnolog√≠as utilizadas

* [Python 3.11](https://www.python.org/)
* [Pandas](https://pandas.pydata.org/)
* [NumPy](https://numpy.org/)
* [Scikit-Learn](https://scikit-learn.org/stable/)
* [Imbalanced-Learn](https://imbalanced-learn.org/stable/)
* [Jupyter Notebook](https://jupyter.org/)
* [Conda](https://docs.conda.io/) ‚Äì gesti√≥n de entornos y dependencias

---

## ‚úÖ PASOS DEL PROYECTO

El desarrollo del proyecto se llev√≥ a cabo en un **notebook** que documenta paso a paso el an√°lisis y modelado, complementado con la posibilidad de trasladar funciones a scripts dentro de la carpeta `src/` para facilitar su reutilizaci√≥n.  

### üìí Pasos en el Notebook

**Encabezado y configuraci√≥n inicial**  
   - Importaci√≥n de librer√≠as y verificaci√≥n de versiones.  
   - Definici√≥n del estilo visual para gr√°ficos.  

1. **Carga del dataset y vista r√°pida**  
   - Inspecci√≥n inicial de filas, columnas y tipos de datos.  
   - Revisi√≥n de valores nulos y duplicados.  

2. **Calidad de datos y tratamiento de nulos**  
   - Revisi√≥n de datos duplicados, valores nulos y estad√≠sticas descriptivas. 
   - Reemplazo de nulos en `Tenure` por **0** (clientes con menos de un a√±o en el banco).  

3. **An√°lisis exploratorio de datos (EDA)**  
   - Distribuci√≥n de la variable objetivo `Exited` y detecci√≥n de desbalance.  
   - Distribuciones de variables num√©ricas (CreditScore, Age, Balance, EstimatedSalary).  
   - Relaci√≥n de variables categ√≥ricas (`Geography`, `Gender`) con el churn.  
   - Detecci√≥n de valores extremos mediante boxplots.  

4. **Preprocesamiento de datos**  
   - Selecci√≥n de variables (`features` y `target`).  
   - Codificaci√≥n de variables categ√≥ricas con One-Hot Encoding.  
   - Escalado de variables num√©ricas con `StandardScaler`.  

5. **Partici√≥n de datos (train/valid/test)**  
   - Divisi√≥n estratificada en proporci√≥n 60/20/20.  

6. **Entrenamiento de modelos base (sin balanceo)**  
   - √Årbol de Decisi√≥n.  
   - Random Forest.  
   - Regresi√≥n Log√≠stica.  

7. **Aplicaci√≥n de t√©cnicas de balanceo**  
   - **Oversampling**: duplicaci√≥n de la clase minoritaria.  
   - **Undersampling**: reducci√≥n de la clase mayoritaria.  

8. **Entrenamiento de modelos con balanceo**  
   - √Årbol de Decisi√≥n con Oversampling.  
   - Random Forest con Oversampling.  
   - Regresi√≥n Log√≠stica con Oversampling.
   - √Årbol de Decisi√≥n con Undersampling.  
   - Random Forest con Undersampling.  
   - Regresi√≥n Log√≠stica con Undersampling. 

9. **Evaluaci√≥n final en conjunto de prueba (test)**  
    - Selecci√≥n del mejor modelo.  
    - Evaluaci√≥n final con m√©tricas en datos no vistos.  

10. **Conclusiones y recomendaciones finales**  
    - An√°lisis exploratorio de datos (EDA).  
    - Modelos base.  
    - T√©cnicas de balanceo.
    - Modelo final seleccionado.
    - Recomentaciones.

---

### ‚öôÔ∏è Pasos previstos para `src/`

Aunque el an√°lisis principal se realiz√≥ en el notebook, la carpeta `src/` permite trasladar el c√≥digo a funciones reutilizables y m√°s limpias para futuros proyectos:

- **`preprocessing.py`**  
  - Funci√≥n para cargar y limpiar el dataset.  
  - Funci√≥n para codificaci√≥n de variables categ√≥ricas.  
  - Funci√≥n para escalar variables num√©ricas.  
  - Funci√≥n para dividir los datos en train/valid/test.  

- **`models.py`**  
  - Funci√≥n para entrenar y evaluar un modelo con m√©tricas (F1, AUC-ROC).  
  - Funci√≥n para aplicar oversampling o undersampling al conjunto de entrenamiento.  
  - Funci√≥n para comparar m√∫ltiples modelos y seleccionar el mejor.  

---

## ‚öôÔ∏è Estructura del proyecto

```bash
.
‚îú‚îÄ‚îÄ datasets/
‚îÇ   ‚îî‚îÄ‚îÄ Churn.csv            # Dataset principal
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ sprint10_analysis.ipynb # Notebook con el an√°lisis y modelos
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ preprocessing.py     # Funciones de preprocesamiento
‚îÇ   ‚îî‚îÄ‚îÄ models.py            # Funciones de entrenamiento y evaluaci√≥n
‚îú‚îÄ‚îÄ reports/
‚îÇ   ‚îî‚îÄ‚îÄ figures/             # Gr√°ficos y visualizaciones
‚îú‚îÄ‚îÄ environment.yml          # Archivo para recrear el entorno con conda
‚îî‚îÄ‚îÄ README.md
```

---

## üìë Dataset

**Archivo:** `/datasets/Churn.csv`

**Columnas principales:**

* `RowNumber` ‚Üí √≠ndice de cadena de datos
* `CustomerId` ‚Üí identificador de cliente √∫nico
* `Surname` ‚Üí apellido
* `CreditScore` ‚Üí puntaje de cr√©dito
* `Geography` ‚Üí pa√≠s de residencia
* `Gender` ‚Üí g√©nero
* `Age` ‚Üí edad
* `Tenure` ‚Üí a√±os de relaci√≥n con el banco
* `Balance` ‚Üí saldo en cuenta
* `NumOfProducts` ‚Üí n√∫mero de productos bancarios
* `HasCrCard` ‚Üí tarjeta de cr√©dito (1 s√≠, 0 no)
* `IsActiveMember` ‚Üí actividad del cliente (1 s√≠, 0 no)
* `EstimatedSalary` ‚Üí salario estimado
* `Exited` ‚Üí cliente se fue (1 s√≠, 0 no)

---

## üìä Conclusiones y Resultados Esperados

Durante el desarrollo del proyecto se entrenaron y compararon diferentes modelos de clasificaci√≥n para predecir la deserci√≥n de clientes en **Beta Bank**.  
A continuaci√≥n, se resumen los resultados m√°s relevantes:

---

### üîπ Modelos base (sin balanceo de clases)

- **√Årbol de Decisi√≥n:**  
  - F1 = **0.588**  
  - AUC-ROC = **0.843**  
  El modelo logra un F1 aceptable cercano al umbral (0.59), pero a√∫n inestable. El AUC-ROC muestra una buena capacidad de distinguir entre clientes que permanecen y los que abandonan.

- **Random Forest:**  
  - F1 = **0.586**  
  - AUC-ROC = **0.876**  
  El bosque aleatorio super√≥ al √Årbol de Decisi√≥n en discriminaci√≥n (AUC-ROC m√°s alto), aunque el F1 sigue por debajo del umbral.

- **Regresi√≥n Log√≠stica:**  
  - F1 = **0.327**  
  - AUC-ROC = **0.791**  
  El modelo lineal mostr√≥ limitaciones claras para capturar el churn, con un F1 muy bajo aunque con una separaci√≥n moderada de clases.

---

### üîπ Modelos con balanceo de clases

Dado el fuerte desbalance (80% permanecen vs 20% abandonan), se aplicaron **Oversampling** y **Undersampling**.  

- **√Årbol de Decisi√≥n con Oversampling:**  
  - F1 = **0.572**  
  - AUC-ROC = **0.855**  
  Mejor√≥ la estabilidad en las predicciones, aunque no logr√≥ superar el umbral de F1 ‚â• 0.59.

- **Random Forest con Oversampling:**  
  - F1 = **0.630**  
  - AUC-ROC = **0.876**  
  Se convirti√≥ en el modelo m√°s s√≥lido, superando claramente el umbral de F1 y manteniendo un alto AUC-ROC.  

- **Regresi√≥n Log√≠stica con Oversampling:**  
  - F1 = **0.521**  
  - AUC-ROC = **0.794**  
  La m√©trica F1 mejor√≥ respecto al modelo base, pero sigue siendo insuficiente frente al requisito.

- **√Årbol de Decisi√≥n con Undersampling:**  
  - F1 = **0.568**  
  - AUC-ROC = **0.858**  
  Buen desempe√±o, aunque ligeramente inferior al oversampling.

- **Random Forest con Undersampling:**  
  - F1 = **0.601**  
  - AUC-ROC = **0.870**  
  El modelo mantuvo un rendimiento alto, aunque algo menor al Random Forest con Oversampling.

- **Regresi√≥n Log√≠stica con Undersampling:**  
  - F1 = **0.518**  
  - AUC-ROC = **0.793**  
  Mejor√≥ respecto al modelo base, pero sigue sin ser competitivo.

---

### üöÄ Modelo final en conjunto de prueba

El modelo elegido para la evaluaci√≥n final fue **Random Forest con Oversampling**, ya que:  
- Fue el √∫nico que super√≥ de forma consistente el umbral de **F1 ‚â• 0.59**.  
- Mostr√≥ un equilibrio adecuado entre precisi√≥n y recall.  
- Conserv√≥ un AUC-ROC elevado, demostrando alta capacidad para discriminar entre clientes que permanecen y los que abandonan.

**Resultados en test (datos no vistos):**  
- **F1 = 0.611**  
- **AUC-ROC = 0.860**

---

### ‚úÖ Conclusi√≥n general

El modelo de **Random Forest con Oversampling** se consolida como la mejor alternativa para **Beta Bank**, ya que cumple con el criterio de desempe√±o exigido y ofrece una herramienta confiable para identificar clientes en riesgo de abandono.  
Su implementaci√≥n permitir√° dise√±ar estrategias de retenci√≥n m√°s efectivas, optimizar recursos de marketing y mejorar la fidelizaci√≥n de clientes.

---

## ‚ñ∂Ô∏è Instalaci√≥n y uso

1. **Clonar repositorio**

   ```bash
   git clone https://github.com/cjhirashi/proyecto-sprint-10.git
   ```

2. **Acceder a carpeta del proyecto**

   ```bash
   cd proyecto-sprint-10
   ```

3. **Crear entorno con Conda**

   ```bash
   conda env create -f environment.yml
   ```

4. **Activar el entorno ya creado**

   ```bash
   conda activate tp-sprint-10
   ```

5. **Ejecutar Notebook**

   ```bash
   jupyter notebook notebooks/sprint10_analysis.ipynb
   ```

---

## ‚ôªÔ∏è Gesti√≥n del entorno con Conda

* **Eliminar entorno** (para liberar espacio):

  ```bash
  conda env remove -n tp-sprint-10
  ```

* **Recrear entorno** (a partir del archivo `environment.yml`):

  ```bash
  conda env create -f environment.yml
  conda activate tp-sprint-10
  ```
  
* **Desactivar entorno** (cuando se desea cerrar el entorno):
  
  ```bash
  conda deactivate
  ```

---

## üë®‚Äçüíª Autor

**Carlos Jim√©nez Hirashi**
üíº Data Scientist Jr. | Python & Machine Learning
üìß [cjhirashi@gmail.com](mailto:cjhirashi@gmail.com) ¬∑ üåê [LinkedIn](https://www.linkedin.com/in/cjhirashi)
